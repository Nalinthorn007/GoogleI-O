{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LCEL (LangChain Expression Language) ‡ªÅ‡∫°‡ªà‡∫ô‡∫´‡∫ç‡∫±‡∫á:\n",
    "**LCEL ‡ªÅ‡∫°‡ªà‡∫ô syntax ‡∫Ç‡∫≠‡∫á LangChain ‡∫ó‡∫µ‡ªà‡ªÉ‡∫ä‡ªâ‡ªÉ‡∫ô‡∫Å‡∫≤‡∫ô‡ªÄ‡∫ä‡∫∑‡ªà‡∫≠‡∫°‡∫ï‡ªç‡ªà components ‡∫ï‡ªà‡∫≤‡∫á‡ªÜ‡ªÄ‡∫Ç‡∫ª‡ªâ‡∫≤‡∫î‡ªâ‡∫ß‡∫ç‡∫Å‡∫±‡∫ô ‡ªÅ‡∫•‡∫∞ ‡∫™‡∫≤‡∫°‡∫≤‡∫î‡ªÄ‡∫Æ‡∫±‡∫î‡ªÉ‡∫´‡ªâ‡∫≠‡ªà‡∫≤‡∫ô‡∫á‡ªà‡∫≤‡∫ç. ‡ªÇ‡∫î‡∫ç‡∫°‡∫±‡∫Å‡∫à‡∫∞‡ªÉ‡∫ä‡ªâ‡ªÄ‡∫Ñ‡∫∑‡ªà‡∫≠‡∫á‡ªù‡∫≤‡∫ç | (pipe) ‡ªÄ‡∫û‡∫∑‡ªà‡∫≠‡ªÄ‡∫ä‡∫∑‡ªà‡∫≠‡∫°‡∫ï‡ªç‡ªà components ‡∫ï‡ªà‡∫≤‡∫á‡ªÜ‡ªÉ‡∫ô‡∫•‡∫≥‡∫î‡∫±‡∫ö.**\n",
    "\n",
    "**HumanMessage:**\n",
    "- ‡ªÄ‡∫õ‡∫±‡∫ô class ‡∫™‡∫≥‡∫´‡∫º‡∫±‡∫ö‡∫à‡∫±‡∫î‡ªÄ‡∫Å‡∫±‡∫ö‡∫Ç‡ªç‡ªâ‡∫Ñ‡∫ß‡∫≤‡∫°‡∫Ç‡∫≠‡∫á‡∫ú‡∫π‡ªâ‡ªÉ‡∫ä‡ªâ\n",
    "- ‡ªÅ‡∫ó‡∫ô‡∫Ñ‡∫≥‡∫™‡∫±‡ªà‡∫á ‡∫´‡∫º‡∫∑ ‡∫Ñ‡∫≥‡∫ñ‡∫≤‡∫°‡∫ó‡∫µ‡ªà User ‡∫™‡∫ª‡ªà‡∫á‡∫°‡∫≤ \n",
    "\n",
    "**SystemMessage:**\n",
    "- ‡ªÄ‡∫õ‡∫±‡∫ô class ‡∫™‡∫≥‡∫´‡∫º‡∫±‡∫ö‡∫à‡∫±‡∫î‡ªÄ‡∫Å‡∫±‡∫ö‡∫Ñ‡∫≥‡∫™‡∫±‡ªà‡∫á‡∫Ç‡∫≠‡∫á‡∫•‡∫∞‡∫ö‡∫ª‡∫ö\n",
    "- ‡∫Å‡∫≥‡∫ô‡∫ª‡∫î‡∫ö‡∫ª‡∫î‡∫ö‡∫≤‡∫î ‡ªÅ‡∫•‡∫∞ ‡∫û‡∫∂‡∫î‡∫ï‡∫¥‡∫Å‡∫≥‡∫Ç‡∫≠‡∫á AI\n",
    "- ‡∫ï‡∫±‡ªâ‡∫á‡∫Å‡∫ª‡∫î‡∫•‡∫∞‡∫ö‡∫Ω‡∫ö‡ªÉ‡∫´‡ªâ AI ‡∫õ‡∫∞‡∫ï‡∫¥‡∫ö‡∫±‡∫î‡∫ï‡∫≤‡∫°\n",
    "\n",
    "**StrOutputParser:**\n",
    "- ‡ªÄ‡∫õ‡∫±‡∫ô parser ‡∫ó‡∫µ‡ªà‡∫õ‡ªà‡∫Ω‡∫ô‡∫ú‡∫ª‡∫ô‡∫•‡∫±‡∫ö‡∫à‡∫≤‡∫Å AI model ‡ªÉ‡∫´‡ªâ‡ªÄ‡∫õ‡∫±‡∫ô string\n",
    "- ‡ªÄ‡∫≠‡∫ª‡∫≤‡ªÅ‡∫ï‡ªà‡ªÄ‡∫ô‡∫∑‡ªâ‡∫≠‡ªÉ‡∫ô‡∫Ç‡∫≠‡∫á‡∫Å‡∫≤‡∫ô‡∫ï‡∫≠‡∫ö‡∫Å‡∫±‡∫ö\n",
    "- ‡∫Å‡∫≥‡∫à‡∫±‡∫î metadata ‡ªÅ‡∫•‡∫∞ ‡∫Ç‡ªç‡ªâ‡∫°‡∫π‡∫ô‡∫û‡∫¥‡ªÄ‡∫™‡∫î‡∫≠‡∫∑‡ªà‡∫ô‡ªÜ\n",
    "\n",
    "**Chain:**\n",
    "- ‡ªÄ‡∫õ‡∫±‡∫ô‡∫Å‡∫≤‡∫ô‡ªÄ‡∫ä‡∫∑‡ªà‡∫≠‡∫°‡∫ï‡ªç‡ªà components ‡∫´‡∫º‡∫≤‡∫ç‡ªÇ‡∫ï‡ªÄ‡∫Ç‡∫ª‡ªâ‡∫≤‡∫î‡ªâ‡∫ß‡∫ç‡∫Å‡∫±‡∫ô\n",
    "- ‡∫™‡∫≤‡∫°‡∫≤‡∫î‡ªÄ‡∫Æ‡∫±‡∫î‡∫ß‡∫Ω‡∫Å‡ªÅ‡∫ö‡∫ö‡∫•‡∫≥‡∫î‡∫±‡∫ö‡∫Ç‡∫±‡ªâ‡∫ô‡∫ï‡∫≠‡∫ô\n",
    "- ‡∫ú‡∫ª‡∫ô‡∫•‡∫±‡∫ö‡∫à‡∫≤‡∫Å component ‡∫Å‡ªà‡∫≠‡∫ô‡∫à‡∫∞‡ªÄ‡∫õ‡∫±‡∫ô input ‡∫Ç‡∫≠‡∫á component ‡∫ï‡ªç‡ªà‡ªÑ‡∫õ\n",
    "\n",
    "**ChatPromptTemplate:**\n",
    "- ‡ªÄ‡∫õ‡∫±‡∫ô template ‡∫™‡∫≥‡∫´‡∫º‡∫±‡∫ö‡∫™‡ªâ‡∫≤‡∫á prompts ‡∫™‡∫≥‡∫´‡∫º‡∫±‡∫ö chat models\n",
    "- ‡∫™‡∫≤‡∫°‡∫≤‡∫î‡∫õ‡∫∞‡∫Å‡∫≠‡∫ö‡∫´‡∫º‡∫≤‡∫ç message types ‡ªÄ‡∫Ç‡∫ª‡ªâ‡∫≤‡∫î‡ªâ‡∫ß‡∫ç‡∫Å‡∫±‡∫ô\n",
    "- ‡∫°‡∫µ variables ‡∫ó‡∫µ‡ªà‡∫™‡∫≤‡∫°‡∫≤‡∫î‡∫õ‡ªà‡∫Ω‡∫ô‡ªÅ‡∫õ‡∫á‡∫Ñ‡ªà‡∫≤‡ªÑ‡∫î‡ªâ\n",
    "- ‡∫ä‡ªà‡∫ß‡∫ç‡ªÉ‡∫´‡ªâ‡∫Å‡∫≤‡∫ô‡∫™‡ªâ‡∫≤‡∫á prompts ‡ªÄ‡∫õ‡∫±‡∫ô‡∫•‡∫∞‡∫ö‡∫ª‡∫ö ‡ªÅ‡∫•‡∫∞ ‡∫ô‡∫≥‡ªÉ‡∫ä‡ªâ‡∫Ñ‡∫∑‡∫ô‡ªÑ‡∫î‡ªâ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional\n",
    "```python\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"meta-llama/llama-4-maverick-17b-128e-instruct\",groq_api_key=groq_api_key)\n",
    "model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Response: Hello! I'm doing well, thank you for asking. As a large language model, I don't experience feelings in the same way humans do, but I'm functioning optimally and ready to assist you.\n",
      "\n",
      "How are **you** doing today? Is there anything I can help you with?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.oauth2 import service_account\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "JSON_KEY_PATH = r\"C:\\Users\\Kenshin\\Desktop\\GoogleI-O\\key.json\" \n",
    "PROJECT_ID = os.getenv(\"GOOGLE_CLOUD_PROJECT\") \n",
    "GOOGLE_LOCATION= os.getenv(\"GOOGLE_LOCATION\")\n",
    "\n",
    "try:\n",
    "    # Load credentials\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        JSON_KEY_PATH,\n",
    "        scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "    )\n",
    "    \n",
    "    # Initialize Vertex AI model\n",
    "    model = ChatVertexAI(\n",
    "        model_name=\"gemini-2.5-flash-lite\",  \n",
    "        project=PROJECT_ID,\n",
    "        location=GOOGLE_LOCATION, \n",
    "        credentials=credentials,\n",
    "        temperature=1.0\n",
    "    )\n",
    "    \n",
    "    # Test the model\n",
    "    response = model.invoke(\"Hello! How are you today?\")\n",
    "    print(f\"ü§ñ Response: {response.content}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a professional English to Lao translator. Translate the following English text to Lao language accurately, maintaining the original meaning and tone. Provide only the Lao translation without explanations.\"),\n",
    "    HumanMessage(content=\"Hello, How is going today?\")\n",
    "]\n",
    "\n",
    "result = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ, ‡∫°‡∫∑‡ªâ‡∫ô‡∫µ‡ªâ‡ªÄ‡∫õ‡∫±‡∫ô‡ªÅ‡∫ô‡∫ß‡ªÉ‡∫î?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 56, 'total_tokens': 77, 'completion_time': 0.099357294, 'prompt_time': 0.0013883, 'queue_time': 0.057221749999999995, 'total_time': 0.100745594}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'system_fingerprint': 'fp_c527aa4474', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--fdedd11e-57e1-4787-81e2-008d8b59c1db-0', usage_metadata={'input_tokens': 56, 'output_tokens': 21, 'total_tokens': 77})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ, ‡∫°‡∫∑‡ªâ‡∫ô‡∫µ‡ªâ‡ªÄ‡∫õ‡∫±‡∫ô‡ªÅ‡∫ô‡∫ß‡ªÉ‡∫î?'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser=StrOutputParser()\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ, ‡∫°‡∫∑‡ªâ‡∫ô‡∫µ‡ªâ‡ªÄ‡∫õ‡∫±‡∫ô‡ªÅ‡∫ô‡∫ß‡ªÉ‡∫î?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Using LCEL- chain the components\n",
    "chain=model|parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prompt Templates\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "generic_template=\"You are a professional English to Lao translator. Translate the following English text to Lao language accurately, maintaining the original meaning and tone. Provide only the Lao translation without explanations. Translate the following into {language}:\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",generic_template),(\"user\",\"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=prompt.invoke({\"language\":\"Lao\",\"text\":\"Hello, what is Google I/O?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a professional English to Lao translator. Translate the following English text to Lao language accurately, maintaining the original meaning and tone. Provide only the Lao translation without explanations. Translate the following into Lao:', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello, what is Google I/O?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ, Google I/O ‡ªÅ‡∫°‡ªà‡∫ô‡∫´‡∫ç‡∫±‡∫á?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Chaining together components with LCEL\n",
    "chain=prompt|model|parser\n",
    "chain.invoke({\"language\":\"Lao\",\"text\":\"Hello, what is Google I/O?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
