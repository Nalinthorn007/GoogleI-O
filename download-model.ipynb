{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import json\n",
    "from typing import Optional, List\n",
    "\n",
    "def download_embedding_models(\n",
    "    model_count: int = 1,\n",
    "    save_directory: str = r\"C:\\Users\\Kenshin\\Desktop\\GoogleI-O\\model\",\n",
    "    force_download: bool = False,\n",
    "    use_auth_token: Optional[str] = None,\n",
    "    custom_models: Optional[List[str]] = None\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Download embedding models from Hugging Face based on count specified.\n",
    "    \n",
    "    Args:\n",
    "        model_count (int): Number of models to download (1-10)\n",
    "        save_directory (str): Directory to save the models\n",
    "        force_download (bool): Whether to force re-download even if model exists\n",
    "        use_auth_token (str, optional): Hugging Face authentication token\n",
    "        custom_models (List[str], optional): Custom list of models to choose from\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: List of paths to downloaded models\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default popular embedding models (ordered by popularity/usefulness)\n",
    "    default_models = [\n",
    "        \"sentence-transformers/all-MiniLM-L6-v2\",           # 1. Fast and efficient\n",
    "        \"sentence-transformers/all-mpnet-base-v2\",          # 2. High quality\n",
    "        \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",  # 3. Multilingual\n",
    "        \"sentence-transformers/all-distilroberta-v1\",       # 4. Good balance\n",
    "        \"sentence-transformers/all-MiniLM-L12-v2\",          # 5. Better than L6\n",
    "        \"sentence-transformers/multi-qa-mpnet-base-dot-v1\", # 6. Q&A optimized\n",
    "        \"sentence-transformers/paraphrase-MiniLM-L6-v2\",    # 7. Paraphrase detection\n",
    "        \"sentence-transformers/msmarco-distilbert-base-v4\", # 8. Search optimized\n",
    "        \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\",  # 9. Multi-domain Q&A\n",
    "        \"sentence-transformers/all-roberta-large-v1\"        # 10. Large model\n",
    "    ]\n",
    "    \n",
    "    # Use custom models if provided, otherwise use default\n",
    "    available_models = custom_models if custom_models else default_models\n",
    "    \n",
    "    # Validate model count\n",
    "    if model_count < 1:\n",
    "        model_count = 1\n",
    "    elif model_count > len(available_models):\n",
    "        model_count = len(available_models)\n",
    "        print(f\"‚ö†Ô∏è  Requested {model_count} models, but only {len(available_models)} available. Downloading all.\")\n",
    "    \n",
    "    # Select models to download\n",
    "    models_to_download = available_models[:model_count]\n",
    "    \n",
    "    print(f\"üì• Downloading {model_count} embedding model(s):\")\n",
    "    for i, model in enumerate(models_to_download, 1):\n",
    "        print(f\"  {i}. {model}\")\n",
    "    print()\n",
    "    \n",
    "    # Create save directory\n",
    "    save_path = Path(save_directory)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    downloaded_paths = []\n",
    "    successful_downloads = 0\n",
    "    \n",
    "    for i, model_name in enumerate(models_to_download, 1):\n",
    "        try:\n",
    "            print(f\"[{i}/{model_count}] Processing: {model_name}\")\n",
    "            \n",
    "            # Create model-specific directory\n",
    "            model_dir_name = model_name.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "            model_save_path = save_path / model_dir_name\n",
    "            \n",
    "            # Check if model already exists\n",
    "            if model_save_path.exists() and not force_download:\n",
    "                print(f\"  ‚úì Model already exists, skipping download\")\n",
    "                downloaded_paths.append(str(model_save_path))\n",
    "                successful_downloads += 1\n",
    "                continue\n",
    "            \n",
    "            model_save_path.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Download tokenizer\n",
    "            print(f\"  üìÑ Downloading tokenizer...\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_name,\n",
    "                token=use_auth_token,\n",
    "                trust_remote_code=True,\n",
    "                cache_dir=str(model_save_path)\n",
    "            )\n",
    "            tokenizer.save_pretrained(model_save_path)\n",
    "            \n",
    "            # Download model\n",
    "            print(f\"  ü§ñ Downloading model...\")\n",
    "            model = AutoModel.from_pretrained(\n",
    "                model_name,\n",
    "                token=use_auth_token,\n",
    "                trust_remote_code=True,\n",
    "                cache_dir=str(model_save_path)\n",
    "            )\n",
    "            model.save_pretrained(model_save_path)\n",
    "            \n",
    "            # Save basic model info\n",
    "            model_info = {\n",
    "                \"model_name\": model_name,\n",
    "                \"model_path\": str(model_save_path),\n",
    "                \"tokenizer_vocab_size\": tokenizer.vocab_size if hasattr(tokenizer, 'vocab_size') else None\n",
    "            }\n",
    "            \n",
    "            with open(model_save_path / \"model_info.json\", \"w\") as f:\n",
    "                json.dump(model_info, f, indent=2)\n",
    "            \n",
    "            print(f\"  ‚úÖ Successfully downloaded to: {model_save_path}\")\n",
    "            downloaded_paths.append(str(model_save_path))\n",
    "            successful_downloads += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error downloading {model_name}: {str(e)}\")\n",
    "            # Clean up partial download\n",
    "            if 'model_save_path' in locals() and model_save_path.exists():\n",
    "                import shutil\n",
    "                shutil.rmtree(model_save_path)\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nüéâ Download Summary:\")\n",
    "    print(f\"  ‚úÖ Successfully downloaded: {successful_downloads}/{model_count} models\")\n",
    "    print(f\"  üìÅ Saved to: {save_directory}\")\n",
    "    \n",
    "    if downloaded_paths:\n",
    "        print(f\"  üìã Downloaded models:\")\n",
    "        for path in downloaded_paths:\n",
    "            model_name = Path(path).name.replace(\"_\", \"/\")\n",
    "            print(f\"    - {model_name}\")\n",
    "    \n",
    "    return downloaded_paths\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Download 1 model\n",
    "    # download_embedding_models(model_count=1)\n",
    "    \n",
    "    # Download 2 models\n",
    "    # download_embedding_models(model_count=2)\n",
    "    \n",
    "    # Download 5 models\n",
    "    # download_embedding_models(model_count=5)\n",
    "    \n",
    "    # Download custom models\n",
    "    custom_list = [\n",
    "        \"BAAI/bge-m3\", \n",
    "        # \"cross-encoder/ms-marco-MiniLM-L12-v2\", \n",
    "        # \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", \n",
    "        # \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    ]\n",
    "    hf_token= os.getenv(\"HuggingFaceToken\")\n",
    "    download_embedding_models(model_count=1, custom_models=custom_list, use_auth_token=hf_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
